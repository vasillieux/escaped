version: '3.8'

services:
  redis:
    image: "redis:alpine"
    ports:
      - "6379:6379" 
    volumes:
      - redis_data:/data 

  submitter: 
    build:
      context: .
      dockerfile: base.Dockerfile
    env_file:
      .env
    depends_on:
      - redis
    volumes:
      - $PWD/web3_orgs.txt:/app/web3_orgs.txt:r
    environment:
      PYTHONPATH: /app
    command: ["python", "escaped/submit_jobs.py"]

  crawler_worker:
    build:
      context: .
      dockerfile: base.Dockerfile
    env_file:
      .env
    depends_on:
      - redis
    volumes:
    # TODO ... make github authenticaton
      - ~/.config/gh:/root/.config/gh:ro
      - ./analysis_output:/app/analysis_output:z # Persist analysis output
    environment:
      PYTHONPATH: /app
    # Command to start the RQ worker for the crawler queue
    command: >
      sh -c "
      echo 'Waiting for Redis...' &&
      while ! nc -z redis 6379; do
        sleep 1;
      done;
      echo 'Redis is up, starting crawler worker.';
      rq worker -c escaped.config escaped_crawler_queue --url redis://redis:6379/0
      "
    deploy: 
      replicas: 1 

  analyzer_worker:
    build:
      context: .
      dockerfile: base.Dockerfile
    env_file:
      .env
    depends_on:
      - redis
    volumes:
      - ~/.config/gh:/root/.config/gh:ro 
      - ./analysis_output:/app/analysis_output 
    environment:
      PYTHONPATH: /app
    command: >
      sh -c "
      echo 'Waiting for Redis...' &&
      while ! nc -z redis 6379; do
        sleep 1;
      done;
      echo 'Redis is up, starting analyzer worker.';
      rq worker -c escaped.config escaped_analyzer_queue --url redis://redis:6379/1
      "
    deploy:
      replicas: 1 

volumes:
  redis_data: